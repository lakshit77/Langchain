{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load documents from PDF files\n",
    "[Document Loader Link](https://python.langchain.com/docs/how_to/#document-loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the directory containing PDF files\n",
    "pdf_directory = './docs'\n",
    "\n",
    "# List to hold loaded documents\n",
    "documents = []\n",
    "\n",
    "# Get all PDF files from the directory\n",
    "file_paths = [os.path.join(pdf_directory, file) for file in os.listdir(pdf_directory) if file.endswith('.md')]\n",
    "\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "# Load PDFs using PyPDFLoader\n",
    "for file_path in file_paths:\n",
    "    loader = UnstructuredMarkdownLoader(file_path)\n",
    "    documents.extend(loader.load())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Split the documents into chunks\n",
    "[Text Split Link](https://python.langchain.com/docs/how_to/#text-splitters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Split is require because LLM have different context size, also when storing in vector database it is always good to store in chunk\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000, \n",
    "        chunk_overlap=200\n",
    "    )\n",
    "text_splitted_document = text_splitter.split_documents(documents) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create embeddings and store in vector database\n",
    "[Embedding Link](https://python.langchain.com/docs/how_to/#embedding-models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(text_splitted_document, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Query Processing and retrieving data\n",
    "[Retrieving Link](https://python.langchain.com/docs/how_to/#retrievers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Taxable Investments\\n\\nBrokerage Account: $64,230\\n\\nGrowth YTD: 6.8%\\n\\nAllocation: 65% individual stocks, 35% ETFs\\n\\nCryptocurrency: $5,890\\n\\nGrowth YTD: -12.3%\\n\\nHoldings: BTC, ETH, SOL\\n\\nDebt Overview\\n\\nMortgage: $298,400 remaining\\n\\nInterest Rate: 3.25%\\n\\nMonthly Payment: $1,850 (including escrow)\\n\\nPayoff Date: November 2049\\n\\nCar Loan: $18,650 remaining\\n\\nInterest Rate: 4.1%\\n\\nMonthly Payment: $385\\n\\nPayoff Date: March 2027\\n\\nCredit Cards: $0 (paid in full monthly)\\n\\nFinancial Goals Progress\\n\\nShort-term Goals (1 year)\\n\\nEmergency Fund: $18,000 target, currently at $15,000 (83%)\\n\\nHome Repair Fund: $10,000 target, currently at $7,500 (75%)\\n\\nVacation Fund: $3,500 target, currently at $2,800 (80%)\\n\\nMedium-term Goals (1-5 years)\\n\\nNew Vehicle Purchase: $35,000 target, currently at $8,000 (23%)\\n\\nHome Renovation: $25,000 target, currently at $0 (0%)\\n\\nLong-term Goals\\n\\nRetirement: On track based on current contribution rate\\n\\nCollege Fund for Kids: Behind schedule, need to increase contributions'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Fixed mortgage payment\"\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "result = retriever.invoke(query)\n",
    "print(len(result))\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create QA chain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: how is my health status\n",
      "\n",
      "Answer:\n",
      "  Based on the provided documents, your health status appears to be generally\n",
      "good. You have a history of seasonal allergies and mild penicillin sensitivity,\n",
      "but no other significant health concerns. Your blood pressure and cholesterol\n",
      "levels have improved over the past year, and you are actively working towards\n",
      "your fitness goals. You are also taking steps to improve your nutrition and\n",
      "overall wellness through regular exercise and supplements. However, it is\n",
      "important to continue monitoring your blood pressure and cholesterol levels, as\n",
      "well as following your doctor's recommendations for reducing sodium intake and\n",
      "maintaining a healthy weight. Source: Personal Health Journal - 2023-2024,\n",
      "Medication Log, Exercise Routine, Recent Doctor Visits, Fitness Goals for 2024,\n",
      "Nutrition Notes.\n"
     ]
    }
   ],
   "source": [
    "query = \"how is my health status\"\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "print(\"\\nQuestion:\", query)\n",
    "# print(\"\\nAnswer:\", result[\"result\"])\n",
    "import textwrap\n",
    "\n",
    "wrapped_text = textwrap.fill(result[\"result\"], width=80)  # Adjust width as needed\n",
    "print(\"\\nAnswer:\\n\", wrapped_text)\n",
    "# print(\"\\nSources:\")\n",
    "# for i, doc in enumerate(result[\"source_documents\"]):\n",
    "#     print(f\"Source {i+1}: {doc.metadata.get('source', 'Unknown')}, Page {doc.metadata.get('page', 'Unknown')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "# Create a custom prompt template\n",
    "template = \"\"\"\n",
    "You are a helpful assistant that answers questions based on provided documents.\n",
    "Provide proper formatted answer with proper heading and sub headings and paragraphs\n",
    "\n",
    "Context information from documents:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer the question based only on the provided context. If you don't know the answer or cannot find it in the context, say \"I couldn't find this information in the provided documents.\" Include specific details and cite the sources of information.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: how is my health status\n",
      "\n",
      "Answer: \n",
      "Health Status:\n",
      "\n",
      "Based on the provided documents, your health status appears to be generally good. You are 42 years old with a height of 5'10\" and a blood type of O+. You have a history of seasonal allergies and mild penicillin sensitivity, but no other significant health concerns.\n",
      "\n",
      "Vital Statistics:\n",
      "\n",
      "Your vital statistics record shows that your weight has fluctuated between 181-188 lbs over the past year. Your blood pressure has also varied, but has generally been within a healthy range. Your resting heart rate has remained consistent at around 70-75 bpm. Your cholesterol levels have improved since your last annual physical, but are still slightly high. Your blood sugar levels have also been within a healthy range.\n",
      "\n",
      "Medication:\n",
      "\n",
      "You are currently taking Lisinopril (10mg) daily for blood pressure management, as well as Zyrtec (10mg) as needed for seasonal allergies. You also take a daily supplement of Vitamin D (2000 IU) and a multivitamin.\n",
      "\n",
      "Exercise Routine:\n",
      "\n",
      "Your exercise routine consists of a mix of cardio and strength training, with rest days and outdoor activities incorporated. This is a well-rounded routine that can help improve overall health and fitness.\n",
      "\n",
      "Recent Doctor Visits:\n",
      "\n",
      "Your most recent annual physical showed some\n"
     ]
    }
   ],
   "source": [
    "query = \"how is my health status\"\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "print(\"\\nQuestion:\", query)\n",
    "\n",
    "# wrapped_text = textwrap.fill(result[\"result\"], width=80)  # Adjust width as needed\n",
    "# print(\"\\nAnswer:\\n\", wrapped_text)\n",
    "print(\"\\nAnswer:\", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yt_envv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
