{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load documents from PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the directory containing PDF files\n",
    "pdf_directory = './docs'\n",
    "\n",
    "# List to hold loaded documents\n",
    "documents = []\n",
    "\n",
    "# Get all PDF files from the directory\n",
    "file_paths = [os.path.join(pdf_directory, file) for file in os.listdir(pdf_directory) if file.endswith('.md')]\n",
    "\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "# Load PDFs using PyPDFLoader\n",
    "for file_path in file_paths:\n",
    "    loader = UnstructuredMarkdownLoader(file_path)\n",
    "    documents.extend(loader.load())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Split the documents into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Split is require because LLM have different context size, also when storing in vector database it is always good to store in chunk\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000, \n",
    "        chunk_overlap=200\n",
    "    )\n",
    "text_splitted_document = text_splitter.split_documents(documents) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create embeddings and store in vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(text_splitted_document, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Query Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'MOBILE APPLICATION REDESIGN\\n\\nManaged the redesign of a mobile application, improving user engagement by 45% and increasing daily active users by 30%.\\n\\nDATA VISUALIZATION DASHBOARD\\n\\nDeveloped a data visualization dashboard that enabled customers to gain insights from complex datasets, increasing customer satisfaction scores by 22%.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"GlideRecord\"\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3},\n",
    ")\n",
    "result = retriever.invoke(query)\n",
    "print(len(result))\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create QA chain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI(temperature=0)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready! Ask questions about your documents.\n",
      "\n",
      "Answer:  Based on the information provided, your financial health appears to be in good shape. You have a solid budget in place and are consistently meeting your monthly expenses. Your investment portfolio is also performing well, with positive growth in all accounts. However, it may be beneficial to discuss rebalancing your 401(k) and exploring tax-efficient investing strategies with your financial advisor. Additionally, it may be worth considering increasing contributions to your college fund for your children to catch up on your savings goals. Overall, it seems like you are on track to meet your long-term goals, but it may be helpful to review your insurance coverage and explore options for refinancing your car loan to potentially save money in the long run.\n",
      "\n",
      "Sources:\n",
      "Source 1: ./docs/personal_financial_record.md, Page Unknown\n",
      "Source 2: ./docs/personal_financial_record.md, Page Unknown\n",
      "Source 3: ./docs/personal_financial_record.md, Page Unknown\n",
      "\n",
      "Answer:  According to the context, your blood pressure has been recorded at 128/84, 132/86, 127/83, 130/85, and 135/88 at various doctor visits. It is slightly elevated but has improved since your last annual physical. Your goal is to lower it to under 120/80 without increasing medication.\n",
      "\n",
      "Sources:\n",
      "Source 1: ./docs/personal_health_records.md, Page Unknown\n",
      "Source 2: ./docs/personal_health_records.md, Page Unknown\n",
      "Source 3: ./docs/personal_health_records.md, Page Unknown\n"
     ]
    }
   ],
   "source": [
    "print(\"Ready! Ask questions about your documents.\")\n",
    "while True:\n",
    "    query = input(\"\\nQuestion (type 'exit' to quit): \")\n",
    "    if query.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    result = qa_chain.invoke({\"query\": query})\n",
    "    print(\"\\nAnswer:\", result[\"result\"])\n",
    "    print(\"\\nSources:\")\n",
    "    for i, doc in enumerate(result[\"source_documents\"]):\n",
    "        print(f\"Source {i+1}: {doc.metadata.get('source', 'Unknown')}, Page {doc.metadata.get('page', 'Unknown')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KrishNaikAgenticAi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
